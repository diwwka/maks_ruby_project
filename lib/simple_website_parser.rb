require 'mechanize'
require 'open-uri'
require_relative 'logger_manager'
require_relative 'item'
require_relative 'cart'

module Tarnovetskyi
  class SimpleWebsiteParser
    attr_reader :item_collection

    def initialize(config)
      @config = config
      # ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ñƒ Ð±ÐµÑ€ÑƒÑ‚ÑŒÑÑ Ð· ÑÐµÐºÑ†Ñ–Ñ— 'web_scraping'
      @parser_config = config['web_scraping']
      
      # Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ Mechanize Ð°Ð³ÐµÐ½Ñ‚Ð° 
      @agent = Mechanize.new
      @agent.user_agent_alias = 'Mac Safari' # ÐŸÑ€Ð¸ÐºÐ¸Ð´Ð°Ñ”Ð¼Ð¾ÑÑŒ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð¾Ð¼
      
      # Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ ÐºÐ¾Ð»ÐµÐºÑ†Ñ–Ñ— (ÐšÐ¾ÑˆÐ¸ÐºÐ°) [cite: 400]
      @item_collection = Tarnovetskyi::Cart.new
      
      Tarnovetskyi::LoggerManager.log_processed_file("Parser initialized with config")
    end

    def start_parse
      # --- Ð ÐÐÐ”ÐžÐœÐ†Ð—ÐÐ¦Ð†Ð¯ Ð¡Ð¢ÐžÐ Ð†ÐÐšÐ˜ ---
      # ÐÐ° ÑÐ°Ð¹Ñ‚Ñ– books.toscrape.com Ñ” 50 ÑÑ‚Ð¾Ñ€Ñ–Ð½Ð¾Ðº.
      # ÐœÐ¸ Ð³ÐµÐ½ÐµÑ€ÑƒÑ”Ð¼Ð¾ Ð²Ð¸Ð¿Ð°Ð´ÐºÐ¾Ð²Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð²Ñ–Ð´ 1 Ð´Ð¾ 50.
      random_page_number = rand(1..50)
      
      # Ð¤Ð¾Ñ€Ð¼ÑƒÑ”Ð¼Ð¾ Ð½Ð¾Ð²Ñƒ URL-Ð°Ð´Ñ€ÐµÑÑƒ Ð´Ð¸Ð½Ð°Ð¼Ñ–Ñ‡Ð½Ð¾
      start_url = "http://books.toscrape.com/catalogue/page-#{random_page_number}.html"
      
      Tarnovetskyi::LoggerManager.log_processed_file("ðŸŽ² Random page selected: ##{random_page_number}")
      Tarnovetskyi::LoggerManager.log_processed_file("Start parsing from: #{start_url}")

      # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ–
      unless check_url_response(start_url)
        Tarnovetskyi::LoggerManager.log_error("Start URL is not accessible: #{start_url}")
        return
      end

      # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð¾Ñ€Ñ–Ð½ÐºÑƒ
      page = @agent.get(start_url)
      
      # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ð½Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸
      product_links = extract_products_links(page)
      
      puts "ÐÐ° ÑÑ‚Ð¾Ñ€Ñ–Ð½Ñ†Ñ– ##{random_page_number} Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ #{product_links.size} ÐºÐ½Ð¸Ð³."
      puts "ÐžÐ±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ 3 Ð²Ð¸Ð¿Ð°Ð´ÐºÐ¾Ð²Ñ– ÐºÐ½Ð¸Ð³Ð¸..."

      # --- Ð ÐÐÐ”ÐžÐœÐ†Ð—ÐÐ¦Ð†Ð¯ ÐšÐÐ˜Ð“ ---
      # Ð—Ð°Ð¼Ñ–ÑÑ‚ÑŒ .first(3) Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ .sample(3), Ñ‰Ð¾Ð± Ð²Ð·ÑÑ‚Ð¸ Ð²Ð¸Ð¿Ð°Ð´ÐºÐ¾Ð²Ñ– ÐºÐ½Ð¸Ð³Ð¸ Ð·Ñ– ÑÐ¿Ð¸ÑÐºÑƒ
      product_links.sample(3).each do |link|
        full_link = page.uri.merge(link)
        parse_product_page(full_link)
        sleep(1) # Ð•Ñ‚Ð¸Ñ‡Ð½Ð° Ð¿Ð°ÑƒÐ·Ð°
      end
      
      Tarnovetskyi::LoggerManager.log_processed_file("Parsing finished. Total items in session: #{@item_collection.items.size}")
    end

    private

    # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ” Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ð½Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸ Ð·Ñ– ÑÑ‚Ð¾Ñ€Ñ–Ð½ÐºÐ¸ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ñƒ [cite: 406]
    def extract_products_links(page)
      # Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€ Ð· ÐºÐ¾Ð½Ñ„Ñ–Ð³Ñƒ (product_link_selector: "h3 a")
      selector = @parser_config['product_link_selector']
      page.search(selector).map { |link| link['href'] }
    end

    # ÐŸÐ°Ñ€ÑÐ¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñƒ ÑÑ‚Ð¾Ñ€Ñ–Ð½ÐºÑƒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñƒ [cite: 408]
    def parse_product_page(url)
      begin
        Tarnovetskyi::LoggerManager.log_processed_file("Processing page: #{url}")
        page = @agent.get(url)

        # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ð´Ð°Ð½Ñ–, Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‡Ð¸ Ð¼ÐµÑ‚Ð¾Ð´Ð¸ extract_...
        name = extract_product_name(page)
        price_str = extract_product_price(page)
        # Ð§Ð¸ÑÑ‚Ð¸Ð¼Ð¾ Ñ†Ñ–Ð½Ñƒ Ð²Ñ–Ð´ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñƒ Â£
        price = price_str.gsub('Â£', '').to_f 
        description = extract_product_description(page)
        category = extract_product_category(page)
        image_url = extract_product_image_url(page)
        
        # Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ 
        saved_image_path = save_image(image_url, name, category)

        # Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¾Ð±'Ñ”ÐºÑ‚Ð° Item
        item = Tarnovetskyi::Item.new(
          name: name,
          price: price,
          description: description,
          category: category,
          image_path: saved_image_path
        )

        # Ð”Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð² ÐºÐ¾ÑˆÐ¸Ðº
        @item_collection.add_item(item)
        puts "  -> Ð”Ð¾Ð´Ð°Ð½Ð¾: #{name}"

      rescue StandardError => e
        Tarnovetskyi::LoggerManager.log_error("Error parsing page #{url}: #{e.message}")
      end
    end

    # --- ÐœÐµÑ‚Ð¾Ð´Ð¸ Ð²Ð¸Ñ‚ÑÐ³ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð°Ð½Ð¸Ñ… (Extractors) [cite: 409-412] ---

    def extract_product_name(page)
      # ÐÐ° Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ–Ð¹ ÑÑ‚Ð¾Ñ€Ñ–Ð½Ñ†Ñ– Ð½Ð°Ð·Ð²Ð° Ð·Ð°Ð·Ð²Ð¸Ñ‡Ð°Ð¹ Ð² h1
      page.search("h1").text.strip
    end

    def extract_product_price(page)
      selector = @parser_config['product_price_selector']
      page.search(selector).text.strip
    end

    def extract_product_description(page)
      selector = @parser_config['product_description_selector']
      # description Ð¼Ð¾Ð¶Ðµ Ð½Ðµ Ð±ÑƒÑ‚Ð¸, Ñ‚Ð¾Ð¼Ñƒ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾
      element = page.search(selector).first
      element ? element.text.strip : "No description"
    end
    
    def extract_product_category(page)
      selector = @parser_config['product_category_selector']
      page.search(selector).text.strip
    end

    def extract_product_image_url(page)
        selector = @parser_config['product_image_selector']
        # Ð‘ÐµÐ·Ð¿ÐµÑ‡Ð½Ðµ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°
        element = page.search(selector).first
        
        if element && element['src']
            rel_url = element['src']
            page.uri.merge(rel_url).to_s
        else
            # ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ”Ð¼Ð¾ Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ð½Ð° Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ Ð°Ð±Ð¾ nil, ÑÐºÑ‰Ð¾ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾
            Tarnovetskyi::LoggerManager.log_error("Image not found for page: #{page.uri}")
            "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg" # Ð”ÐµÑ„Ð¾Ð»Ñ‚Ð½Ð° ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ°
        end
    end

    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° URL [cite: 413]
    def check_url_response(url)
      begin
        # Mechanize head request
        @agent.head(url)
        true
      rescue Mechanize::ResponseCodeError
        false
      end
    end

    # ÐœÐµÑ‚Ð¾Ð´ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ 
    def save_image(url, filename, category)
      # ÐžÑ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ Ð½Ð°Ð·Ð²Ð¸ Ð´Ð»Ñ Ñ„Ð°Ð¹Ð»Ñƒ
      safe_filename = filename.gsub(/[^a-zA-Z0-9\-\_]/, '_').downcase
      safe_category = category.gsub(/[^a-zA-Z0-9\-\_]/, '_').downcase
      
      # Ð¨Ð»ÑÑ…: media/category/filename.jpg
      media_dir = @config['default']['media_dir']
      category_dir = File.join(media_dir, safe_category)
      
      # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ Ð¿Ð°Ð¿ÐºÑƒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ—, ÑÐºÑ‰Ð¾ Ð½ÐµÐ¼Ð°Ñ”
      FileUtils.mkdir_p(category_dir)
      
      local_path = File.join(category_dir, "#{safe_filename}.jpg")
      
      # --- ÐÐžÐ’Ð ÐŸÐ•Ð Ð•Ð’Ð†Ð ÐšÐ ---
      # Ð¯ÐºÑ‰Ð¾ Ñ„Ð°Ð¹Ð» Ð²Ð¶Ðµ Ñ–ÑÐ½ÑƒÑ”, Ð¼Ð¸ Ð½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Ð¹Ð¾Ð³Ð¾ Ð·Ð½Ð¾Ð²Ñƒ
      if File.exist?(local_path)
        Tarnovetskyi::LoggerManager.log_processed_file("Image already exists (Skipping download): #{local_path}")
        return local_path
      end
      # ----------------------

      # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ (ÑÐºÑ‰Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ Ð½ÐµÐ¼Ð°Ñ”)
      begin
        Tarnovetskyi::LoggerManager.log_processed_file("Downloading image: #{url}")
        @agent.get(url).save(local_path)
        local_path
      rescue StandardError => e
        Tarnovetskyi::LoggerManager.log_error("Failed to download image: #{url}")
        "media/default.jpg"
      end
    end
  end
end